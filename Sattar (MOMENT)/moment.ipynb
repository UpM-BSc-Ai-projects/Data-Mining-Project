{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ae5e595b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: momentfm in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (0.1.4)\n",
      "Requirement already satisfied: huggingface-hub==0.24.0 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from momentfm) (0.24.0)\n",
      "Requirement already satisfied: numpy==1.25.2 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from momentfm) (1.25.2)\n",
      "Requirement already satisfied: torch~=2.0 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from momentfm) (2.5.1)\n",
      "Requirement already satisfied: transformers==4.33.3 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from momentfm) (4.33.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from huggingface-hub==0.24.0->momentfm) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from huggingface-hub==0.24.0->momentfm) (2025.2.0)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from huggingface-hub==0.24.0->momentfm) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from huggingface-hub==0.24.0->momentfm) (6.0.2)\n",
      "Requirement already satisfied: requests in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from huggingface-hub==0.24.0->momentfm) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from huggingface-hub==0.24.0->momentfm) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from huggingface-hub==0.24.0->momentfm) (4.12.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from transformers==4.33.3->momentfm) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from transformers==4.33.3->momentfm) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from transformers==4.33.3->momentfm) (0.5.3)\n",
      "Requirement already satisfied: networkx in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from torch~=2.0->momentfm) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from torch~=2.0->momentfm) (3.1.5)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from torch~=2.0->momentfm) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from sympy==1.13.1->torch~=2.0->momentfm) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub==0.24.0->momentfm) (0.4.6)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from jinja2->torch~=2.0->momentfm) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from requests->huggingface-hub==0.24.0->momentfm) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from requests->huggingface-hub==0.24.0->momentfm) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from requests->huggingface-hub==0.24.0->momentfm) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\4310129\\appdata\\local\\anaconda3\\envs\\ai417-dl\\lib\\site-packages (from requests->huggingface-hub==0.24.0->momentfm) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "!pip install momentfm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "198ffe16",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from momentfm import MOMENTPipeline\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch import nn\n",
    "from torchmetrics import MeanSquaredError, MeanAbsoluteError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "80d2a95e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(116504, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>SMA_200</th>\n",
       "      <th>ATR_168</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-01-09 17:00:00</td>\n",
       "      <td>1.326128e+09</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.9</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.83495</td>\n",
       "      <td>0.032560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-01-09 18:00:00</td>\n",
       "      <td>1.326132e+09</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.5</td>\n",
       "      <td>5.84455</td>\n",
       "      <td>0.033155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-01-09 19:00:00</td>\n",
       "      <td>1.326136e+09</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.5</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.85465</td>\n",
       "      <td>0.033750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-01-09 20:00:00</td>\n",
       "      <td>1.326139e+09</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.86475</td>\n",
       "      <td>0.033750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-01-09 21:00:00</td>\n",
       "      <td>1.326143e+09</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>6.6</td>\n",
       "      <td>5.87485</td>\n",
       "      <td>0.033750</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime     Timestamp  Open  High  Low  Close  SMA_200   ATR_168\n",
       "0 2012-01-09 17:00:00  1.326128e+09   6.9   6.9  6.5    6.5  5.83495  0.032560\n",
       "1 2012-01-09 18:00:00  1.326132e+09   6.5   6.6  6.5    6.5  5.84455  0.033155\n",
       "2 2012-01-09 19:00:00  1.326136e+09   6.5   6.6  6.5    6.6  5.85465  0.033750\n",
       "3 2012-01-09 20:00:00  1.326139e+09   6.6   6.6  6.6    6.6  5.86475  0.033750\n",
       "4 2012-01-09 21:00:00  1.326143e+09   6.6   6.6  6.6    6.6  5.87485  0.033750"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "df = pd.read_csv(\"../data/preprocessed_hourly_data.csv\", parse_dates=['datetime'])\n",
    "df = df.sort_values('datetime').reset_index(drop=True)\n",
    "\n",
    "# Select features and target\n",
    "features = ['Open', 'High', 'Low', 'Close', 'SMA_200', 'ATR_168']\n",
    "target = 'Close'\n",
    "data = df[features].values.astype(np.float32)\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "99259d63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 512) (360,)\n",
      "(115633, 6, 512) (115633, 360)\n"
     ]
    }
   ],
   "source": [
    "# Normalize features channel-wise (fit on train portion only)\n",
    "n_total = len(data)\n",
    "split_idx = int(0.8 * n_total)\n",
    "\n",
    "# Create sliding windows\n",
    "input_len = 512\n",
    "horizon = 360 # forecast horizon, 360 hours = 15 days\n",
    "\n",
    "windows, targets = [], []\n",
    "for i in range(n_total - input_len - horizon + 1):\n",
    "    inp = data[i:i+input_len, :].T  # shape: (channels, 512)\n",
    "    tgt = data[i+input_len:i+input_len+horizon, features.index(target)]  # Close prices\n",
    "    windows.append(inp)\n",
    "    targets.append(tgt)\n",
    "print(inp.shape, tgt.shape)\n",
    "\n",
    "windows = np.stack(windows)   # shape: (N_windows, channels, input_len=512)\n",
    "targets = np.stack(targets)   # shape: (N_windows, horizon=360)\n",
    "\n",
    "print(windows.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "a4ff4627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of windows: 115633\n"
     ]
    }
   ],
   "source": [
    "# Split into train/val/test (chronological)\n",
    "n_windows = len(windows)\n",
    "print(f\"Total number of windows: {n_windows}\")\n",
    "\n",
    "train_end = int(0.8 * n_windows)\n",
    "val_end = int(0.9 * n_windows)\n",
    "train_X, val_X, test_X = windows[:train_end], windows[train_end:val_end], windows[val_end:]\n",
    "train_y, val_y, test_y = targets[:train_end], targets[train_end:val_end], targets[val_end:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0bdb9061",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ForecastDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = torch.from_numpy(X).float()  # shape (N, C, L): (N_windows, channels=6, input_len=512)\n",
    "        self.Y = torch.from_numpy(Y).float()  # shape (N, H): (N_windows, horizon=360)\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    def __getitem__(self, idx):\n",
    "        timeseries = self.X[idx]              # (C, L)\n",
    "        # print(timeseries.shape)\n",
    "        forecast = self.Y[idx]               # (H,)\n",
    "        input_mask = torch.ones(timeseries.shape[-1])  # (L,), all observed\n",
    "        # print(input_mask.shape)\n",
    "        return timeseries, forecast, input_mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "140609d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ForecastDataset(train_X, train_y)\n",
    "val_ds   = ForecastDataset(val_X,   val_y)\n",
    "test_ds  = ForecastDataset(test_X,  test_y)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=16, shuffle=True)\n",
    "val_loader   = DataLoader(val_ds,   batch_size=16, shuffle=False)\n",
    "test_loader  = DataLoader(test_ds,  batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "32ed6597",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\4310129\\AppData\\Local\\anaconda3\\envs\\AI417-DL\\lib\\site-packages\\momentfm\\models\\moment.py:174: UserWarning: Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\n",
      "  warnings.warn(\"Only reconstruction head is pre-trained. Classification and forecasting heads must be fine-tuned.\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MOMENTPipeline(\n",
       "  (normalizer): RevIN()\n",
       "  (tokenizer): Patching()\n",
       "  (patch_embedding): PatchEmbedding(\n",
       "    (value_embedding): Linear(in_features=8, out_features=512, bias=False)\n",
       "    (position_embedding): PositionalEmbedding()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 6)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1-7): 7 x T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=384, bias=False)\n",
       "              (o): Linear(in_features=384, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseGatedActDense(\n",
       "              (wi_0): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wi_1): Linear(in_features=512, out_features=1024, bias=False)\n",
       "              (wo): Linear(in_features=1024, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (act): NewGELUActivation()\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (head): ForecastingHead(\n",
       "    (flatten): Flatten(start_dim=-2, end_dim=-1)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (linear): Linear(in_features=32768, out_features=360, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load MOMENT pipeline for forecasting\n",
    "model = MOMENTPipeline.from_pretrained(\n",
    "    \"AutonLab/MOMENT-1-small\",\n",
    "    model_kwargs={\n",
    "        'task_name': 'forecasting',\n",
    "        'forecast_horizon': horizon,\n",
    "        # 'forecast_dim': 1,\n",
    "        'head_dropout': 0.1,\n",
    "        'weight_decay': 0.0,\n",
    "        'freeze_encoder': True,\n",
    "        'freeze_embedder': True,\n",
    "        'freeze_head': False\n",
    "    }\n",
    ")\n",
    "model.init()\n",
    "# model = moment_pipe.model  # The PyTorch model with forecasting head\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2c6622f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "\n",
    "# Loss functions\n",
    "mse_loss_fn = nn.MSELoss()\n",
    "huber_loss_fn = nn.SmoothL1Loss()\n",
    "mse_loss_fn.to(device)\n",
    "huber_loss_fn.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "\n",
    "# Metrics\n",
    "metric_mse = MeanSquaredError().to(device)\n",
    "metric_mae = MeanAbsoluteError().to(device)\n",
    "\n",
    "# Scheduler\n",
    "from torch.optim.lr_scheduler import OneCycleLR\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "scheduler = OneCycleLR(optimizer, max_lr=1e-4, total_steps=total_steps)\n",
    "max_grad_norm = 5.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a99c31",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\4310129\\AppData\\Local\\anaconda3\\envs\\AI417-DL\\lib\\site-packages\\torch\\_dynamo\\eval_frame.py:632: UserWarning: torch.utils.checkpoint: the use_reentrant parameter should be passed explicitly. In version 2.5 we will raise an exception if use_reentrant is not passed. use_reentrant=False is recommended, but if you need to preserve the current default behavior, you can pass use_reentrant=True. Refer to docs for more details on the differences between the two variants.\n",
      "  return fn(*args, **kwargs)\n",
      "c:\\Users\\4310129\\AppData\\Local\\anaconda3\\envs\\AI417-DL\\lib\\site-packages\\torch\\utils\\checkpoint.py:87: UserWarning: None of the inputs have requires_grad=True. Gradients will be None\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Training loop\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_losses = []\n",
    "    for series, target, mask in train_loader:\n",
    "        series = series.to(device)     # (batch, L, C)\n",
    "        target = target.to(device)     # (batch, H)\n",
    "        mask   = mask.to(device)       # (batch, L)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(x_enc=series, input_mask=mask)  # forward pass # shape [B, 360] from forecasting head\n",
    "        # print(output.forecast.shape, target.shape)\n",
    "        # loss = mse_loss_fn(output.forecast, target)\n",
    "        loss = huber_loss_fn(output.forecast[:, 3, :], target)\n",
    "        loss.backward()\n",
    "\n",
    "        # torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
    "        optimizer.step()\n",
    "        # scheduler.step()\n",
    "        \n",
    "        train_losses.append(loss.item())\n",
    "    avg_train_loss = np.mean(train_losses)\n",
    "\n",
    "    model.eval()\n",
    "    val_losses = []\n",
    "    metric_mse.reset(); metric_mae.reset()\n",
    "    with torch.no_grad():\n",
    "        for series, target, mask in val_loader:\n",
    "            series = series.to(device)     # (batch, L, C)\n",
    "            target = target.to(device)     # (batch, H)\n",
    "            mask   = mask.to(device)       # (batch, L)\n",
    "\n",
    "            output = model(x_enc=series, input_mask=mask)\n",
    "            val_loss = huber_loss_fn(output.forecast[:, 3, :], target)\n",
    "            val_losses.append(val_loss.item())\n",
    "            preds = output.forecast[:, 3, :].contiguous()\n",
    "            metric_mse(preds, target)\n",
    "            metric_mae(preds, target)\n",
    "    avg_val_loss = np.mean(val_losses)\n",
    "    val_mse = metric_mse.compute().item()\n",
    "    val_mae = metric_mae.compute().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss {avg_train_loss:.4f} | Val Loss {avg_val_loss:.4f}  | Val MSE {val_mse:.4f}, Val MAE {val_mae:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b01c0a92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test MSE: 25419528.0000, Test MAE: 3614.6968, Test Huber: 3615.6266\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "test_losses = []\n",
    "metric_mse.reset(); metric_mae.reset()\n",
    "with torch.no_grad():\n",
    "    for series, target, mask in test_loader:\n",
    "        series, target, mask = series.to(device), target.to(device), mask.to(device)\n",
    "        output = model(x_enc=series, input_mask=mask)\n",
    "\n",
    "        preds = output.forecast[:, 3, :].contiguous()\n",
    "        metric_mse(preds, target)\n",
    "        metric_mae(preds, target)\n",
    "\n",
    "        # For reporting Huber:\n",
    "        test_losses.append(huber_loss_fn(output.forecast[:, 3, :], target).item())\n",
    "test_mse = metric_mse.compute().item()\n",
    "test_mae = metric_mae.compute().item()\n",
    "test_huber = np.mean(test_losses)\n",
    "\n",
    "print(f\"Test MSE: {test_mse:.4f}, Test MAE: {test_mae:.4f}, Test Huber: {test_huber:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95a409f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "AI417-DL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
